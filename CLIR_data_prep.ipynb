{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets tensorflow pandas python-terrier transformers sklearn tf-keras sentence-transformers sentencepiece torchvision torchaudio\n",
        "%pip install --upgrade datasets ipywidgets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: tensorflow in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.0.2)\nRequirement already satisfied: python-terrier in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.10.0)\nRequirement already satisfied: transformers in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (4.39.3)\nCollecting sklearn\n  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l-\b \berror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m More information is available at\n  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: datasets in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: ipywidgets in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (8.1.2)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (3.12.2)\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (1.25.0)\nRequirement already satisfied: pyarrow>=12.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (12.0.1)\nRequirement already satisfied: pyarrow-hotfix in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (4.65.0)\nRequirement already satisfied: xxhash in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (3.9.3)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (0.21.4)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (23.0)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (6.0)\nRequirement already satisfied: comm>=0.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\nRequirement already satisfied: traitlets>=4.3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\nRequirement already satisfied: widgetsnbextension~=4.0.10 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipywidgets) (4.0.10)\nRequirement already satisfied: jupyterlab-widgets~=3.0.10 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipywidgets) (3.0.10)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.6.3)\nRequirement already satisfied: backcall in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: decorator in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\nRequirement already satisfied: matplotlib-inline in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\nRequirement already satisfied: pickleshare in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\nRequirement already satisfied: pygments>=2.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\nRequirement already satisfied: stack-data in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: executing>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\nRequirement already satisfied: pure-eval in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import mltable\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "import pyterrier as pt\n",
        "from transformers import pipeline, AutoModel, AutoTokenizer, TFAutoModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "print(pt.__version__)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712269325617
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "data_asset = ml_client.data.get(\"ir-project\", version=\"1\")\n",
        "\n",
        "base_path = data_asset.path\n",
        "filenames = [\"de_train\", \"en_train\", \"fr_train\"]\n",
        "\n",
        "dataframes = {}\n",
        "for filename in filenames:\n",
        "    file_path = os.path.join(base_path, filename + '.csv')\n",
        "    dataframes[filename] = pd.read_csv(file_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455676
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249453365
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed=42"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455708
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  text = text.replace(\"_START_ARTICLE_\", \" \")\n",
        "  text = text.replace(\"_START_PARAGRAPH_\", \";\")\n",
        "  text = text.replace(\"_START_SECTION_\", \" \")\n",
        "  text = text.replace(\"_NEWLINE_\", \" \")\n",
        "  \n",
        "  allowed = set(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,;?!$%₤£€&*/[{}] \\\\\")\n",
        "  cleaned_text = ''.join(char for char in text if char in allowed)\n",
        "  \n",
        "  return cleaned_text"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455738
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes['en_train']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455777
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes['de_train']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455815
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes['fr_train']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455852
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {'en': dataframes['en_train'],\n",
        "            'de': dataframes['de_train'],\n",
        "            'fr': dataframes['fr_train']}\n",
        "\n",
        "for lang in datasets.keys():\n",
        "  df = datasets[lang]\n",
        "  print('language:', lang)\n",
        "  print('# articles:', len(df['text']))\n",
        "\n",
        "  articles = []\n",
        "  for i, example in tqdm(df.iterrows(), total=len(df)):\n",
        "    text = clean_text(example['text'].decode('utf-8') if isinstance(example['text'], bytes) else example['text'])\n",
        "    version_id = int(example['version_id'].decode('utf-8') if isinstance(example['version_id'], bytes) else example['version_id'])\n",
        "    wikidata_id = example['wikidata_id'].decode('utf-8') if isinstance(example['wikidata_id'], bytes) else example['wikidata_id']\n",
        "    articles.append({'text': text, 'version_id': version_id, 'wikidata_id': wikidata_id})\n",
        "    \n",
        "      \n",
        "  datasets[lang] = pd.DataFrame(articles)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455883
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['en']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455935
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets['en']['text']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249455976
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "langs = ['en', 'de', 'fr']\n",
        "output_path = 'Users/kgar/'\n",
        "\n",
        "for lang in langs:\n",
        "    datasets[lang].to_csv(os.path.join(output_path, lang + '_train_formatted.csv'))\n",
        "datasets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456015
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = datasets.copy()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456051
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "langs = ['en', 'de', 'fr']\n",
        "\n",
        "for lang in langs:\n",
        "    df[lang]['title'] = df[lang]['text'].apply(lambda x: x.split(';')[0])\n",
        "    df[lang]['text'] = df[lang]['text'].apply(lambda x: ';'.join(x.split(';')[1:]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456082
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['en'].head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['en'].to_csv(os.path.join(output_path, 'en' + '_train_formatted_with_titles.csv'))\n",
        "df['de'].to_csv(os.path.join(output_path, 'de' + '_train_formatted_with_titles.csv'))\n",
        "df['fr'].to_csv(os.path.join(output_path, 'fr' + '_train_formatted_with_titles.csv'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456142
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = 'Users/kgar/'\n",
        "filenames = [\"de_train_formatted_with_titles\",\n",
        "             \"en_train_formatted_with_titles\",\n",
        "             \"fr_train_formatted_with_titles\"\n",
        "            ]\n",
        "\n",
        "df = {}\n",
        "\n",
        "for filename in filenames:\n",
        "    file_path = os.path.join(output_path, filename + '.csv')\n",
        "    dataframes[filename[:2]] = pd.read_csv(file_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456171
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456206
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_en = dataframes['en']\n",
        "dataset_de = dataframes['de']\n",
        "dataset_fr = dataframes['fr']\n",
        "\n",
        "dataset_en['wikidata_id'] = dataset_en['wikidata_id'].astype(str)\n",
        "dataset_de['wikidata_id'] = dataset_de['wikidata_id'].astype(str)\n",
        "dataset_fr['wikidata_id'] = dataset_fr['wikidata_id'].astype(str)\n",
        "\n",
        "common_de_ids = set(dataset_en['wikidata_id']).intersection(set(dataset_de['wikidata_id']))\n",
        "\n",
        "common_de_en = dataset_en[dataset_en['wikidata_id'].isin(common_de_ids)]\n",
        "common_de_de = dataset_de[dataset_de['wikidata_id'].isin(common_de_ids)]\n",
        "common_de = pd.concat([common_de_en, common_de_de], ignore_index=True)\n",
        "common_de = common_de.reset_index()\n",
        "\n",
        "\n",
        "common_fr_ids = set(dataset_en['wikidata_id']).intersection(set(dataset_fr['wikidata_id']))\n",
        "common_fr_en = dataset_en[dataset_en['wikidata_id'].isin(common_fr_ids)]\n",
        "common_fr_fr = dataset_fr[dataset_fr['wikidata_id'].isin(common_fr_ids)]\n",
        "common_fr = pd.concat([common_fr_en, common_fr_fr], ignore_index=True)\n",
        "common_fr = common_fr.reset_index()\n",
        "\n",
        "common_de_fr_ids = common_de_ids.intersection(common_fr_ids)\n",
        "common_de_fr = pd.concat([\n",
        "    dataset_de[dataset_de['wikidata_id'].isin(common_de_fr_ids)],\n",
        "    dataset_fr[dataset_fr['wikidata_id'].isin(common_de_fr_ids)],\n",
        "    dataset_en[dataset_en['wikidata_id'].isin(common_de_fr_ids)]\n",
        "], ignore_index=True)\n",
        "common_de_fr = common_de_fr.reset_index()\n",
        "\n",
        "\n",
        "print('number of common articles across en and de:', len(common_de))\n",
        "print('number of common articles across en and fr:', len(common_fr))\n",
        "print('number of common articles across en, de and fr:', len(common_de_fr))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456237
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_de[common_de['wikidata_id'] == 'Q191828']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_de_fr[common_de_fr['wikidata_id'] == 'Q191828']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456325
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_fr[common_fr['wikidata_id'] == 'Q191828']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456374
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_de.to_csv(os.path.join(output_path,'common_de_final.csv'))\n",
        "print('common_de')\n",
        "common_fr.to_csv(os.path.join(output_path,'common_fr_final.csv'))\n",
        "print('common_fr')\n",
        "common_de_fr.to_csv(os.path.join(output_path,'common_de_fr_final.csv'))\n",
        "print('common_de_fr')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1712249456404
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}